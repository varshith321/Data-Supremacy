{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_jqd04QH.csv')\n",
    "test = pd.read_csv('test_GYi4Gz5.csv')\n",
    "sub = pd.read_csv('sample_submission_sxfcbdx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# #Replacing Null values of Company_type to Other\n",
    "data['company_type'].fillna('NpO', inplace = True)\n",
    "test['company_type'].fillna('NpO', inplace = True)\n",
    "\n",
    "#replacing with medium company size\n",
    "data['company_size'].fillna('50-99', inplace  = True)\n",
    "test['company_size'].fillna('50-99', inplace  = True)\n",
    "\n",
    "# # #Managing all values accordingly\n",
    "data.experience[data.experience == '>20'] = 20 \n",
    "data.experience[data.experience == '<1'] = 1 \n",
    "\n",
    "test.experience[test.experience == '>20'] = 20 \n",
    "test.experience[test.experience == '<1'] = 1 \n",
    "\n",
    "# #Replacing NULL values in experience with median\n",
    "data['experience'].fillna(9, inplace = True)\n",
    "test['experience'].fillna(9, inplace = True)\n",
    "\n",
    "# #Replacing all values in major decipline with 'Other\n",
    "data['major_discipline'].fillna('Other', inplace = True)\n",
    "test['major_discipline'].fillna('Other', inplace = True)\n",
    "\n",
    "# #Handling all the values \n",
    "data.last_new_job[data.last_new_job == '>4'] = 5 \n",
    "test.last_new_job[test.last_new_job == '>4'] = 5 \n",
    "\n",
    "# #Replscing all the NULL values with Mode\n",
    "data['last_new_job'].fillna(2, inplace = True)\n",
    "test['last_new_job'].fillna(2, inplace = True)\n",
    "\n",
    "# #Replacing all the NULL values in education_evel with mode\n",
    "data['education_level'].fillna('Masters', inplace = True)\n",
    "test['education_level'].fillna('Masters', inplace = True) \n",
    "\n",
    "# #Replacing all the NULL values in enrolled university with mode\n",
    "data['enrolled_university'].fillna('Part time course', inplace = True)\n",
    "test['enrolled_university'].fillna('Part time course', inplace = True)\n",
    "\n",
    "# #Filling NULL values with mode\n",
    "data.gender.fillna('Other', inplace =  True) #data['gender'].mode()[0]\n",
    "test.gender.fillna('Other', inplace =  True) #test['gender'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['target'] ,axis = 1)\n",
    "y = data['target'].copy()\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "for i in X.columns:\n",
    "    if X[i].dtype == 'object':\n",
    "        if len(list(X[i].unique())) >=2:\n",
    "            #cols.append(i)\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le.fit(X[i].astype(str))\n",
    "            X[i] = le.transform(X[i].astype(str))\n",
    "            X_test[i] = le.transform(X_test[i].astype(str))\n",
    "            #X_val[i] =   le.transform(X_val[i].astype(str))\n",
    "            #X_test[i] =  le.transform(X_test[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = pd.concat([X.get(['enrollee_id','city','city_development_index', 'gender', 'relevent_experience', 'experience',\n",
    "                                                                            'last_new_job', 'training_hours' ]),\n",
    "                           pd.get_dummies(X['enrolled_university'], prefix='enrolled_university'),\n",
    "                           pd.get_dummies(X['education_level'], prefix='education_level'),\n",
    "                           pd.get_dummies(X['major_discipline'], prefix='major_discipline'),\n",
    "                           pd.get_dummies(X['company_size'], prefix='company_size'),\n",
    "                           pd.get_dummies(X['company_type'], prefix='company_type')],axis=1)\n",
    "\n",
    "X_test = pd.concat([X_test.get(['enrollee_id','city','city_development_index', 'gender', 'relevent_experience', 'experience',\n",
    "                                                                            'last_new_job', 'training_hours' ]),\n",
    "                           pd.get_dummies(X_test['enrolled_university'], prefix='enrolled_university'),\n",
    "                           pd.get_dummies(X_test['education_level'], prefix='education_level'),\n",
    "                           pd.get_dummies(X_test['major_discipline'], prefix='major_discipline'),\n",
    "                           pd.get_dummies(X_test['company_size'], prefix='company_size'),\n",
    "                           pd.get_dummies(X_test['company_type'], prefix='company_type')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Embedding, Flatten, Input, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from time import time\n",
    "import datetime\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.04, #0.04 is best\n",
    "          \"num_leaves\": 18, #18 best case\n",
    "           \"max_bin\": 500,  #500 is best\n",
    "          #\"feature_fraction\": 0.5,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 10,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 100, #100 best case \n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.3\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384652\tvalid_0's gini: 0.271582\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.3846\tvalid_0's gini: 0.271618\n",
      "[Fold 1/5 Prediciton:]\n",
      "[Fold 2/5]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384652\tvalid_0's gini: 0.271582\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.3846\tvalid_0's gini: 0.271618\n",
      "[Fold 2/5 Prediciton:]\n",
      "[Fold 3/5]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384652\tvalid_0's gini: 0.271582\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.3846\tvalid_0's gini: 0.271618\n",
      "[Fold 3/5 Prediciton:]\n",
      "[Fold 4/5]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384652\tvalid_0's gini: 0.271582\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.3846\tvalid_0's gini: 0.271618\n",
      "[Fold 4/5 Prediciton:]\n",
      "[Fold 5/5]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384652\tvalid_0's gini: 0.271582\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.3846\tvalid_0's gini: 0.271618\n",
      "[Fold 5/5 Prediciton:]\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "   \n",
    "    #watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    # Train the model! We pass in a max of 1,600 rounds (with early stopping after 70)\n",
    "    # and the custom metric (maximize=True tells xgb that higher metric is better)\n",
    "    \n",
    "    lgb_model = lgb.train(params, lgb.Dataset(X_train, label=y_train), 200, \n",
    "                  lgb.Dataset(X_val, label=y_val), verbose_eval=100, \n",
    "                  feval=gini_lgb, early_stopping_rounds=100)\n",
    "\n",
    "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37386043, 0.08716797, 0.33701305, ..., 0.1102164 , 0.28389835,\n",
       "       0.24531097])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
