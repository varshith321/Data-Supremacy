{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data = pd.read_csv('train_jqd04QH.csv')\n",
    "test = pd.read_csv('test_GYi4Gz5.csv')\n",
    "\n",
    "# #Replacing Null values of Company_type to Other\n",
    "data['company_type'].fillna('NpO', inplace = True)\n",
    "test['company_type'].fillna('NpO', inplace = True)\n",
    "\n",
    "#replacing with medium company size\n",
    "data['company_size'].fillna('50-99', inplace  = True)\n",
    "test['company_size'].fillna('50-99', inplace  = True)\n",
    "\n",
    "# # #Managing all values accordingly\n",
    "data.experience[data.experience == '>20'] = 20 \n",
    "data.experience[data.experience == '<1'] = 1 \n",
    "\n",
    "test.experience[test.experience == '>20'] = 20 \n",
    "test.experience[test.experience == '<1'] = 1 \n",
    "\n",
    "# #Replacing NULL values in experience with median\n",
    "data['experience'].fillna(9, inplace = True)\n",
    "test['experience'].fillna(9, inplace = True)\n",
    "\n",
    "# #Replacing all values in major decipline with 'Other\n",
    "data['major_discipline'].fillna('Other', inplace = True)\n",
    "test['major_discipline'].fillna('Other', inplace = True)\n",
    "\n",
    "# #Handling all the values \n",
    "data.last_new_job[data.last_new_job == '>4'] = 5 \n",
    "test.last_new_job[test.last_new_job == '>4'] = 5 \n",
    "\n",
    "# #Replscing all the NULL values with Mode\n",
    "data['last_new_job'].fillna(2, inplace = True)\n",
    "test['last_new_job'].fillna(2, inplace = True)\n",
    "\n",
    "# #Replacing all the NULL values in education_evel with mode\n",
    "data['education_level'].fillna('Masters', inplace = True)\n",
    "test['education_level'].fillna('Masters', inplace = True) \n",
    "\n",
    "# #Replacing all the NULL values in enrolled university with mode\n",
    "data['enrolled_university'].fillna('Part time course', inplace = True)\n",
    "test['enrolled_university'].fillna('Part time course', inplace = True)\n",
    "\n",
    "# #Filling NULL values with mode\n",
    "data.gender.fillna('Other', inplace =  True) #data['gender'].mode()[0]\n",
    "test.gender.fillna('Other', inplace =  True) #test['gender'].mode()[0]\n",
    "\n",
    "X = data.drop(['target'] ,axis = 1)\n",
    "y = data['target'].copy()\n",
    "X_test = test\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "for i in X.columns:\n",
    "    if X[i].dtype == 'object':\n",
    "        if len(list(X[i].unique())) >=2:\n",
    "            #cols.append(i)\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le.fit(X[i].astype(str))\n",
    "            X[i] = le.transform(X[i].astype(str))\n",
    "            X_test[i] = le.transform(X_test[i].astype(str))\n",
    "            #X_val[i] =   le.transform(X_val[i].astype(str))\n",
    "            #X_test[i] =  le.transform(X_test[i].astype(str))\n",
    "            \n",
    "\n",
    "\n",
    "X = pd.concat([X.get(['enrollee_id','city','city_development_index', 'gender', 'relevent_experience', 'experience',\n",
    "                                                                            'last_new_job', 'training_hours' ]),\n",
    "                           pd.get_dummies(X['enrolled_university'], prefix='enrolled_university'),\n",
    "                           pd.get_dummies(X['education_level'], prefix='education_level'),\n",
    "                           pd.get_dummies(X['major_discipline'], prefix='major_discipline'),\n",
    "                           pd.get_dummies(X['company_size'], prefix='company_size'),\n",
    "                           pd.get_dummies(X['company_type'], prefix='company_type')],axis=1)\n",
    "\n",
    "X_test = pd.concat([X_test.get(['enrollee_id','city','city_development_index', 'gender', 'relevent_experience', 'experience',\n",
    "                                                                            'last_new_job', 'training_hours' ]),\n",
    "                           pd.get_dummies(X_test['enrolled_university'], prefix='enrolled_university'),\n",
    "                           pd.get_dummies(X_test['education_level'], prefix='education_level'),\n",
    "                           pd.get_dummies(X_test['major_discipline'], prefix='major_discipline'),\n",
    "                           pd.get_dummies(X_test['company_size'], prefix='company_size'),\n",
    "                           pd.get_dummies(X_test['company_type'], prefix='company_type')],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8684258522601056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.8684258522601056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.8686074320186619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.8686074320186619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.8686074320186619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: LogisticRegression(RobustScaler(input_matrix), C=10.0, dual=False, penalty=l2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.naive_bayes.GaussianNB': {}, 'sklearn.naive_bayes.BernoulliNB': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'fit_prior': [True, False]}, 'sklearn.naive_bayes.MultinomialNB': {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'fit_prior': [True, False]}, 'sklearn.tree.DecisionT....3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
       "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])}}}},\n",
       "        crossover_rate=0.1, cv=5, disable_update_check=False,\n",
       "        early_stop=None, generations=5, max_eval_time_mins=5,\n",
       "        max_time_mins=None, memory=None, mutation_rate=0.9, n_jobs=1,\n",
       "        offspring_size=20, periodic_checkpoint_folder=None,\n",
       "        population_size=20, random_state=None, scoring=None, subsample=1.0,\n",
       "        verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tpot.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50288712, 0.49711288],\n",
       "       [0.89431828, 0.10568172],\n",
       "       [0.77146367, 0.22853633],\n",
       "       ...,\n",
       "       [0.94539752, 0.05460248],\n",
       "       [0.64661663, 0.35338337],\n",
       "       [0.72162237, 0.27837763]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission_sxfcbdx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target'] = pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('tpot.csv',index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
